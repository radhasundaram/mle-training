{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import tarfile\r\n",
    "import urllib\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.svm import SVR\r\n",
    "import joblib\r\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\r\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\r\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\r\n",
    "\r\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\r\n",
    "    os.makedirs(housing_path, exist_ok=True)\r\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\r\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\r\n",
    "    housing_tgz = tarfile.open(tgz_path)\r\n",
    "    housing_tgz.extractall(path=housing_path)\r\n",
    "    housing_tgz.close()\r\n",
    "fetch_housing_data()\r\n",
    "\r\n",
    "\r\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\r\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\r\n",
    "    return pd.read_csv(csv_path)\r\n",
    "housing=load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Stratified Train Test Split based on Household median income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\r\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\r\n",
    "                               labels=[1, 2, 3, 4, 5])\r\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\r\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\r\n",
    "    strat_train_set = housing.loc[train_index]\r\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\r\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\r\n",
    "\r\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\r\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Imputes all the numerical variables with the median, 3 additional transformed variables and categorical variable into dummy variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\r\n",
    "\r\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\r\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\r\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\r\n",
    "    def fit(self, X, y=None):\r\n",
    "        return self  # nothing else to do\r\n",
    "    def transform(self, X):\r\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\r\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\r\n",
    "        if self.add_bedrooms_per_room:\r\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\r\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\r\n",
    "                         bedrooms_per_room]\r\n",
    "\r\n",
    "        else:\r\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\r\n",
    "\r\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "num_pipeline = Pipeline([\r\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\r\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\r\n",
    "        ('std_scaler', StandardScaler()),\r\n",
    "    ])\r\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\r\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\r\n",
    "\r\n",
    "\r\n",
    "num_attribs = list(housing_num)\r\n",
    "cat_attribs = [\"ocean_proximity\"]\r\n",
    "\r\n",
    "full_pipeline = ColumnTransformer([\r\n",
    "        (\"num\", num_pipeline, num_attribs),\r\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\r\n",
    "    ])\r\n",
    "\r\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n    tol=0.001, verbose=False)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "svm_ = SVR(kernel='linear')\r\n",
    "svm_.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\r\n",
    "    print(\"Scores:\", scores)\r\n",
    "    print(\"Mean:\", scores.mean())\r\n",
    "    print(\"Standard deviation:\", scores.std())\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [105342.09141998 112489.24624123 110092.35042753 113403.22892482\n",
      " 110638.90119657 115675.8320024  110703.56887243 114476.89008206\n",
      " 113756.17971227 111520.1120808 ]\n",
      "Mean: 111809.84009600841\n",
      "Standard deviation: 2762.393664321567\n"
     ]
    }
   ],
   "source": [
    "housing_predictions = svm_.predict(housing_prepared)\r\n",
    "scores = cross_val_score(svm_, housing_prepared, housing_labels,\r\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\r\n",
    "svm_rmse_scores = np.sqrt(-scores)\r\n",
    "display_scores(svm_rmse_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['svm_.pkl']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_, \"svm_.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n                                 epsilon=0.1, gamma='auto', kernel='rbf',\n                                 max_iter=-1, shrinking=True, tol=0.001,\n                                 verbose=False),\n                   iid='warn', n_iter=5, n_jobs=None,\n                   param_distributions={'C': range(1, 10),\n                                        'kernel': ('linear', 'rbf')},\n                   pre_dispatch='2*n_jobs', random_state=4, refit=True,\n                   return_train_score=True, scoring='neg_mean_squared_error',\n                   verbose=0)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel': ('linear', 'rbf'), 'C': range(1, 10)}\r\n",
    "svm_ = SVR(gamma='auto')\r\n",
    "clf = RandomizedSearchCV(svm_, parameters,n_iter=5, random_state=4, cv=5,\r\n",
    "                           scoring='neg_mean_squared_error',\r\n",
    "                           return_train_score=True)\r\n",
    "clf.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'kernel': 'linear', 'C': 9}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SVR(C=9, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full pipeline - Data prep and Scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [242.85444128 245.30843271 248.25687042 245.73437052 246.53136196]\n",
      "Mean: 245.73709537963646\n",
      "Standard deviation: 1.7591804561639326\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "\r\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': range(1, 10)}\r\n",
    "num_attribs = list(housing_num)\r\n",
    "cat_attribs = [\"ocean_proximity\"]\r\n",
    "t=  [(\"cat\", OneHotEncoder(), cat_attribs), (\"num\", num_pipeline, num_attribs)]\r\n",
    "col_transform = ColumnTransformer(transformers=t)\r\n",
    "svm_ = SVR(gamma='auto')\r\n",
    "clf = RandomizedSearchCV(svm_, parameters,n_iter=5, random_state=4, cv=5,\r\n",
    "                           scoring='neg_mean_squared_error',\r\n",
    "                           return_train_score=True)\r\n",
    "pipeline = Pipeline(steps=[('prep',col_transform), ('m', clf)])\r\n",
    "scores = cross_val_score(pipeline, housing,housing_labels, scoring='neg_mean_absolute_error',cv=5)\r\n",
    "Final_rmse_scores = np.sqrt(-scores)\r\n",
    "display_scores(Final_rmse_scores)   \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}